Проект: Разработка системы анализа медицинских изображений для эпидемиологического мониторинга COVID-19 (учебный проект)
Обзор проекта
Данный проект разработан как итоговая работа по дисциплине "Базы данных для компьютерного зрения". Его основная цель — разработать комплексную аналитическую платформу для эпидемиологического мониторинга COVID-19, используя метаданные рентгеновских снимков. Проект демонстрирует практическое применение знаний о распределенных файловых системах (HDFS), фреймворках для обработки больших данных (Apache Spark, PySpark, Spark SQL, Spark MLlib), а также навыков ETL-обработки, SQL-аналитики, машинного обучения и визуализации данных.

Цель проекта — применить на практике знания о HDFS, Spark, PySpark и базовых методах машинного обучения для решения реальной задачи анализа медицинских данных.

Используемые технологии
Apache Hadoop (HDFS): Распределенная файловая система для надежного и масштабируемого хранения больших объемов медицинских изображений и метаданных.

Apache Spark: Мощная унифицированная аналитическая платформа для распределенной обработки и анализа данных.

Spark SQL: Используется для выполнения структурированных аналитических запросов с использованием стандартного SQL-синтаксиса.
PySpark: Python API для Spark, применяемый для программной ETL-обработки данных и взаимодействия с DataFrame API.
Spark MLlib: Библиотека машинного обучения для Spark, использованная для построения и оценки модели классификации.
Python: Основной язык программирования для разработки всех скриптов и Jupyter Notebook.

Jupyter Lab: Интерактивная среда разработки, обеспечивающая удобство выполнения кода, отладки и визуализации результатов.

Matplotlib & Seaborn: Библиотеки Python для создания статических и информативных графиков, используемых для визуализации ключевых показателей.

Датасет
В проекте используется публичный датасет COVID-19 Chest X-Ray Dataset, доступный на GitHub: https://github.com/ieee8023/covid-chestxray-dataset.git

Датасет содержит:

Изображения: Рентгеновские снимки (PNG/JPEG) пациентов с различными диагнозами, включая COVID-19, пневмонию и другие патологии.

Метаданные: Файл metadata.csv, содержащий подробную информацию о каждом снимке и пациенте, включая:

patientid: Уникальный идентификатор пациента.
age: Возраст пациента.
sex: Пол пациента.
finding: Диагноз, связанный со снимком.
view: Проекция рентгеновского снимка (например, PA, AP).
date: Дата проведения исследования.
Важное примечание: Исходные файлы датасета (изображения и metadata.csv) НЕ ВКЛЮЧЕНЫ в данный репозиторий из-за их большого размера и условий лицензирования. Также, в связи с тем, что проект разворачивался в Hadoop для получения навыков, данные хранятся в HDFS.



Структура проекта
├── Covid_analysis.ipynb          # Основной Jupyter Notebook с полным циклом анализа данных 
├── LogisticRegression.ipynb      # Jupyter Notebook с реализацией модели логистической регрессии
├── RandomForestClassifier.ipynb  # Jupyter Notebook с реализацией модели случайного леса
├── SparkSQL.ipynb                # Jupyter Notebook с примерами SQL-запросов на Spark SQL
├── Сharts_covid.ipynb            # Jupyter Notebook с кодом для генерации всех визуализаций
├── presentation_images/          # Папка с изображениями слайдов презентации
├── README.md                     # Этот файл с описанием проекта
└── .gitignore                    # Файл для исключения временных файлов и больших данных из Git
Развертывание инфраструктуры
Для запуска проекта требуется кластер Hadoop и Spark. Я осуществила самостоятельное развертывание и настройку всех необходимых компонентов на базе WSL (Ubuntu). Рекомендуется использовать Docker-контейнеры для локального тестирования и более простого воспроизведения среды.

Установка компонентов: Установка Apache Hadoop, Apache Spark и всех необходимых Python-библиотек производилась вручную в среде WSL (Ubuntu), следуя официальной документации.

Hadoop Version: 3.3.6
Spark Version: 3.5.1
Python Version: 3.10.12
Java Version: 11.0.27
Ключевые Python библиотеки:
pyspark==3.5.1
pandas==2.3.0
matplotlib==3.10.3
seaborn==0.13.2
Настройка доступа к Web UI: Доступ к веб-интерфейсам (Hadoop NameNode, Spark History Server, Jupyter Lab) был настроен согласно стандартным рекомендациям по конфигурированию, используя следующие адреса:

Hadoop NameNode UI: http://localhost:9870
Spark History Server UI: http://localhost:18080
Jupyter Lab: http://localhost:8888
Проверка работы HDFS CLI: Работа с HDFS CLI была проверена путем загрузки и чтения тестовых файлов, что подтвердило корректность развертывания распределенной файловой системы.

1. Запуск проекта и анализ
Все этапы проекта реализованы в Jupyter Notebook covid_analysis.ipynb.

Откройте Jupyter Lab: Перейдите по адресу http://localhost:8888 в вашем браузере (или по другому порту, если он настроен).

Откройте covid_analysis.ipynb: Найдите и откройте этот файл в интерфейсе Jupyter Lab.

Последовательно запускайте ячейки:

2. Предобработка данных (ETL)
Цель: Очистка, стандартизация и обогащение исходных метаданных.

Достижения:

Заполнение пропусков: Реализованы индивидуальные стратегии для числовых (age_numeric, temperature, pO2_saturation, leukocyte_count, neutrophil_count, lymphocyte_count — заполнение медианой/средним) и категориальных полей (sex, RT_PCR_positive, survival — заполнение модой или "UNKNOWN").

Удаление дубликатов: Все повторяющиеся записи были удалены.

Унификация диагнозов: Создан новый признак finding_unified (например, "covid-19", "other pneumonia", "tuberculosis", "no finding", "other finding").

Создание новых аналитических признаков: Введены age_group (child, adult, senior), is_covid (бинарный флаг для COVID-19) и извлечены year, month, day из поля date с обработкой множественных форматов.

Комплексный анализ качества данных: Проведен анализ распределения пропущенных значений, выявлены и обработаны аномалии, что задокументировано в выводе Jupyter Notebook.

Сохранение оптимизированной структуры: Очищенные данные сохранены в HDFS по пути /covid_dataset/metadata_optimized/ в формате Parquet. При этом реализовано партиционирование по year и month и бакетирование по finding_unified и sex, что значительно ускоряет аналитические запросы.

3. SQL-аналитика
Цель: Проведение глубокого анализа данных с использованием Spark SQL.

Достижения: Разработано 8 аналитических SQL-запросов, демонстрирующих широкий спектр возможностей Spark SQL:

Запросы с агрегацией и фильтрацией: Распределение диагнозов по полу, топ-локации по случаям COVID-19, процент COVID-случаев по месяцам.

Запросы с оконными функциями: Динамика накопительных случаев COVID-19 (SUM() OVER(...)), скользящее среднее возраста пациентов (AVG() OVER(...)).

Сложные соединения таблиц: Продемонстрировано через самосоединение (Self-Join) для поиска пар пациентов с общими характеристиками, но значительной разницей в возрасте.

Аналитические подзапросы: Использованы для более сложной фильтрации и ранжирования данных (например, поиск локации с самой высокой средней температурой среди активных).

4. Обработка в PySpark и Машинное обучение
Цель: Применение методов машинного обучения для выявления закономерностей и построения предсказательной модели.

Достижения:

Подготовка данных для ML: Категориальные признаки были преобразованы с помощью StringIndexer и OneHotEncoder, а все признаки собраны в единый вектор с помощью VectorAssembler в рамках Spark ML Pipeline.

Построение модели классификации: Обучена модель Random Forest Classifier для предсказания наличия COVID-19 (is_covid) на основе метаданных.

Оценка производительности: Модель достигла высокого показателя Area Under ROC (AUC) = 0.9054 на тестовой выборке, что свидетельствует о её отличной предсказательной способности.

Анализ важности признаков: Выявлены наиболее важные признаки для предсказания: температура, количество лимфоцитов и сатурация кислорода, что согласуется с клиническими данными.

5. Визуализация
Цель: Наглядное представление ключевых эпидемиологических показателей и характеристик пациентов.

Достижения: Созданы 4 визуализации с использованием библиотек Matplotlib и Seaborn, которые включают:

Круговую диаграмму распределения диагнозов.

<img width="723" height="658" alt="загружено" src="https://github.com/user-attachments/assets/66550d83-0e94-4a4d-bf90-bfdf47bb4f95" />

Столбчатую диаграмму распределения случаев COVID-19 по полу.

<img width="618" height="547" alt="загружено (1)" src="https://github.com/user-attachments/assets/f3554493-bd7a-4e1f-869d-b7da1a81f06a" />


Линейный график динамики случаев COVID-19 по годам и месяцам.

<img width="1189" height="590" alt="загружено (2)" src="https://github.com/user-attachments/assets/67488a30-7154-4594-8f89-d9da1f34d59e" />


Столбчатую диаграмму топ-5 локаций по количеству случаев COVID-19.

<img width="989" height="590" alt="загружено (3)" src="https://github.com/user-attachments/assets/7280301f-06ba-4b33-ab0c-049b6dd37c9b" />


Эти графики эффективно интерпретируют полученные аналитические выводы.

Рекомендации по улучшению системы
Для дальнейшего развития и повышения эффективности аналитической платформы можно рассмотреть следующие направления:

Расширение и обогащение данных: Интеграция дополнительных клинических данных (например, история болезни, сопутствующие заболевания) для повышения точности анализов и моделей.

Дальнейшая оптимизация Hive/Spark: Создание внешних таблиц Hive, использование агрегированных представлений (Materialized Views) для ускорения часто используемых отчетов.

Интеграция компьютерного зрения: Разработка и внедрение моделей компьютерного зрения для автоматической классификации самих медицинских изображений (рентгеновских снимков) на предмет патологий, что позволило бы создать более мощную и автоматизированную диагностическую систему.
